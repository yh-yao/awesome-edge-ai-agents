# Awesome Edge AI for Multimodal Agents [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

> A curated list of **papers, frameworks, benchmarks, and applications** for efficient **multimodal agents** (LLMs, text-to-image, speech, world models, etc.) on **mobile and edge devices**.  
> Focused on **inference engines, optimization, and deployment** for real-world use.

---

## ğŸ“‘ Contents
* [Introduction](#-introduction)
* [Papers](#-papers)

  * [Surveys & Overviews](#surveys--overviews)
  * [LLM Inference on Edge](#llm-inference-on-edge)
  * [Multimodal & Generative Models](#multimodal--generative-models)
  * [World Models & Embodied AI](#world-models--embodied-ai)
  * [Agent Systems on Edge](#agent-systems-on-edge)

* [Frameworks & Inference Engines](#-frameworks--inference-engines)
* [Optimization Techniques](#-optimization-techniques)
* [Benchmarks & Datasets](#-benchmarks--datasets)
* [Applications & Use Cases](#-applications--use-cases)
* [Community & Resources](#-community--resources)
* [Concluding Remarks](#concluding-remarks) 

---

## ğŸ”¹ Introduction
The next generation of **AI agents** is multimodal â€” capable of understanding and generating **text, images, speech, video, and embodied interactions**.  
Running these models on **mobile and edge devices** unlocks:
- ğŸŒ **Privacy**: data stays on-device  
- âš¡ **Low latency**: real-time interaction without cloud roundtrips  
- ğŸ“± **Accessibility**: AI everywhere, even offline  
- ğŸ”‹ **Efficiency**: tailored for constrained environments  

This repo tracks the latest progress in making multimodal AI **efficient, deployable, and agent-ready on edge hardware**.

---

## ğŸ“„ Papers

### ğŸ”– Surveys & Overviews
- *Placeholder* â€” (Add key survey papers here)

### ğŸ§  LLM Inference on Edge
- *Placeholder* â€” (e.g., MLC-LLM, llama.cpp papers)

### ğŸ–¼ï¸ Multimodal & Generative Models
- *Placeholder* â€” (text-to-image, speech, video on mobile)

### ğŸŒ World Models & Embodied AI
- *Placeholder* â€” (simulation & agents for robotics/AR/VR on edge)

### ğŸ¤– Agent Systems
- *Placeholder* â€” (agent frameworks adapted to edge/mobile)

---

## âš™ï¸ Frameworks & Inference Engines
- [ONNX Runtime](https://onnxruntime.ai/) â€” Cross-platform inference engine  
- [TensorRT](https://developer.nvidia.com/tensorrt) â€” NVIDIA inference optimization  
- [Core ML](https://developer.apple.com/machine-learning/core-ml/) â€” iOS-native ML framework  
- [MNN](https://www.mnn.zone/) â€” Lightweight inference engine by Alibaba  
- [TensorFlow Lite](https://www.tensorflow.org/lite) â€” ML for mobile/IoT  
- [llama.cpp](https://github.com/ggerganov/llama.cpp) â€” LLM inference in C++  
- [MLC-LLM](https://mlc.ai/mlc-llm/) â€” Bring LLMs to phones, browsers, edge devices  

---

## ğŸ› ï¸ Optimization Techniques
- **Quantization**: INT8, 4-bit, QLoRA  
- **Pruning & Distillation**: Lightweight model variants  
- **Low-Rank Adaptation (LoRA)**: Efficient fine-tuning  
- **Memory-efficient Attention**: FlashAttention, linear attention  
- **Model Compression for Multimodal Models**: distilling diffusion, etc.  

---

## ğŸ“Š Benchmarks & Datasets
- [MLPerf Tiny](https://mlperf.org/tiny/) â€” Benchmark suite for tiny devices  
- [AI Benchmark](https://ai-benchmark.com/) â€” Mobile AI performance testing  
- *Placeholder* â€” (Add multimodal datasets relevant to edge)  

---

## ğŸ“± Applications & Use Cases
- On-device **chat assistants**  
- Real-time **speech translation**  
- AR/VR **embodied agents**  
- Edge **creative tools** (image, video, music generation)  
- Robotics & IoT AI  

---

## ğŸŒ Community & Resources
- [Awesome Edge AI](https://github.com/akshayubhat/awesome-edge-ai) â€” Related list  
- [Awesome Generative AI](https://github.com/steven2358/awesome-generative-ai)  
- [MLC AI Community](https://mlc.ai/)  
- [ONNX Community](https://onnx.ai/)  

---

## ğŸ¤ Contributing
Pull requests are welcome! Please follow the [Awesome List Guidelines](https://github.com/sindresorhus/awesome/blob/main/contributing.md).  

---
â­ï¸ Inspired by the vision of **efficient multimodal agents everywhere** â€” from phones to IoT to autonomous systems.